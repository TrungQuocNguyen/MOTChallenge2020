{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRpfnGjKBcpX"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QYdaolZbBcpl",
    "outputId": "c9c15268-c397-4ac0-cd6f-6bb435ba0caf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0+cu101'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bfCMM879BvKh",
    "outputId": "49dc15b9-8a6f-40ca-d0a6-84fe2db4335c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "6YA4NSnbBzvp",
    "outputId": "b3173979-0aa3-4970-c0c9-3503bd41c525"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%load_ext autoreload\\n%autoreload 2\\n%matplotlib inline\\n\\nimport os\\nimport sys\\n\\n!pip install tqdm lap\\n!pip install https://github.com/timmeinhardt/py-motmetrics/archive/fix_pandas_deprecating_warnings.zip\\n!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\\n!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\\n!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\\n!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\\n!pip install torch-geometric\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "!pip install tqdm lap\n",
    "!pip install https://github.com/timmeinhardt/py-motmetrics/archive/fix_pandas_deprecating_warnings.zip\n",
    "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
    "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
    "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
    "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
    "!pip install torch-geometric\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUJJbEJvBcp1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOE0OIIfBcp-"
   },
   "outputs": [],
   "source": [
    "root_dir1 = \"gdrive/My Drive/Colab Notebooks/cv3dst_exercise/cv3dst_exercise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RAGcynwBcqH"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(root_dir1, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7F75axZsBcqP"
   },
   "outputs": [],
   "source": [
    "from tracker.data_track import MOT16Sequences\n",
    "from tracker.data_obj_detect import MOT16ObjDetect\n",
    "from tracker.object_detector import FRCNN_FPN\n",
    "from tracker.tracker import Tracker\n",
    "from tracker.utils import (plot_sequence, evaluate_mot_accums, get_mot_accum,\n",
    "                           evaluate_obj_detect, obj_detect_transforms)\n",
    "import motmetrics as mm\n",
    "mm.lap.default_solver = 'lap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzmhoXZNBcqX"
   },
   "outputs": [],
   "source": [
    "seq_name = 'MOT16-02'\n",
    "root_dir = \"gdrive/My Drive/Colab Notebooks/cv3dst_exercise/cv3dst_exercise\"\n",
    "data_dir = os.path.join(root_dir, 'data/MOT16')\n",
    "sequences = MOT16Sequences(seq_name, data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LemSI3EpBcqd",
    "outputId": "577e3cff-2a4b-4a72-ddc5-8624d7378efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FRCNN_FPN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_detect_model_file = os.path.join(root_dir, 'models/faster_rcnn_fpn.model')\n",
    "obj_detect_nms_thresh = 0.3\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "# object detector\n",
    "obj_detect = FRCNN_FPN(num_classes=2, nms_thresh=obj_detect_nms_thresh)\n",
    "obj_detect_state_dict = torch.load(obj_detect_model_file,\n",
    "                                   map_location=lambda storage, loc: storage)\n",
    "obj_detect.load_state_dict(obj_detect_state_dict)\n",
    "obj_detect.eval()\n",
    "obj_detect.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8T5br7xKHUZ_"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    img_list = []\n",
    "    gt = {}\n",
    "    img_path = []\n",
    "    vis = {}\n",
    "    seg_img = []\n",
    "    for sample in batch: \n",
    "      img_list.append(sample['img'])\n",
    "      img_path.append(sample['img_path'])\n",
    "      if 'seg_img' in sample: \n",
    "        seg_img.append(torch.tensor(sample['seg_img']))\n",
    "      #tensor_batch['img'] = torch.stack([sample['img']for sample in batch])\n",
    "      for key in sample['gt'].keys():\n",
    "        if key not in gt.keys():\n",
    "          gt[key] = [] \n",
    "        gt[key].append(torch.from_numpy(sample['gt'][key]))\n",
    "      for key in sample['vis'].keys(): \n",
    "        if key not in vis.keys():\n",
    "          vis[key] = [] \n",
    "        vis[key].append(sample['vis'][key])\n",
    "    img = torch.stack(img_list)\n",
    "    for key in gt.keys(): \n",
    "      gt[key] = torch.stack(gt[key])\n",
    "    for key in vis.keys(): \n",
    "      vis[key] = torch.tensor(vis[key])\n",
    "    \n",
    "    \n",
    "    batch_frames = {}\n",
    "    batch_frames['img'] = img\n",
    "    batch_frames['gt'] = gt\n",
    "    batch_frames['img_path'] = img_path\n",
    "    batch_frames['vis'] = vis\n",
    "    if len(seg_img): \n",
    "      seg_img = torch.stack(seg_img)\n",
    "      batch_frames['seg_img'] = seg_img\n",
    "    return batch_frames\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "colab_type": "code",
    "id": "ZyMBUT5BT_mx",
    "outputId": "e4521aeb-6363-4233-d7d6-c21c3b2180c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: MOT16-02\n",
      "Loading data 1\n",
      "Loading data 2\n",
      "Loading data 3\n",
      "Loading data 4\n",
      "Loading data 5\n",
      "Loading data 6\n",
      "Loading data 7\n",
      "Loading data 8\n",
      "Loading data 9\n",
      "Loading data 10\n",
      "Loading data 11\n",
      "Loading data 12\n",
      "Loading data 13\n",
      "Loading data 14\n",
      "Loading data 15\n",
      "torch.Size([5620, 6])\n",
      "Create one graph\n",
      "Loading data 1\n",
      "Loading data 2\n",
      "Loading data 3\n",
      "Loading data 4\n",
      "Loading data 5\n",
      "Loading data 6\n",
      "Loading data 7\n",
      "Loading data 8\n",
      "Loading data 9\n",
      "Loading data 10\n",
      "Loading data 11\n",
      "Loading data 12\n",
      "Loading data 13\n",
      "Loading data 14\n",
      "Loading data 15\n"
     ]
    }
   ],
   "source": [
    "from torchvision.ops import roi_align\n",
    "from tracker.feature_encoder import NodeEncoder, EdgeEncoder\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric import utils\n",
    "\n",
    "def load_data(): \n",
    "    node_encoder = NodeEncoder()\n",
    "    node_encoder.eval()\n",
    "    #node_encoder.to(device)\n",
    "    edge_encoder = EdgeEncoder()\n",
    "    edge_encoder.eval()\n",
    "    #edge_encoder.to(device)\n",
    "\n",
    "    inc = 0\n",
    "    list_boxes = []\n",
    "    list_img = []\n",
    "    edge_list = []\n",
    "    total_node = 0\n",
    "    k = 50\n",
    "    timestamp = []\n",
    "    graph_list = []\n",
    "    edge_features = []\n",
    "\n",
    "    for seq in sequences:# Each seq is a MOT16Sequence object\n",
    "        print(f\"Tracking: {seq}\")\n",
    "        data_loader = DataLoader(seq, batch_size=5, shuffle=False, num_workers = 0, collate_fn = collate_fn) #NOTE: shuffle  = False. This is order sequence !!!!\n",
    "        for batch_frame in data_loader: #batch_frame: size 5x3x1080x1920 (NxCxHxW)\n",
    "            boxes, scores = obj_detect.detect(torch.unsqueeze(batch_frame['img'][0],0)) #boxes: size Bx4, B: number of boxes in that frame\n",
    "            list_boxes.append(boxes)#list of boxes\n",
    "            list_img.append(batch_frame['img'][0]) #list of frame. each frame size CxHxW\n",
    "            timestamp.extend([inc]*boxes.shape[0])\n",
    "            inc = inc+1\n",
    "            print(f\"Loading data {inc}\")\n",
    "            if inc==15: \n",
    "              batch_images = torch.stack(list_img) #batch_images: size NxCxHxW, N: number of frames \n",
    "              detections = roi_align(batch_images, list_boxes, (128,64)) #detections: size KxCx128x64, K: number of boxes in 15 frames \n",
    "              #detections = detections.to(device)\n",
    "              node_embeddings = node_encoder(detections)  #size  Kx32\n",
    "\n",
    "          #######1. Create adjacency matrix and add it to the graph\n",
    "              for boxes_perframe in list_boxes: \n",
    "\n",
    "                  num_node = boxes_perframe.size()[0]\n",
    "                  current_nodes = torch.unsqueeze(node_embeddings[total_node: total_node + num_node],1)\n",
    "                  other_nodes = torch.cat([node_embeddings[:total_node],node_embeddings[total_node + num_node:]])\n",
    "                  total_node = total_node + num_node\n",
    "\n",
    "                  matrix_norm = (current_nodes-other_nodes).norm(dim = 2)\n",
    "                  _,targetnodes_idx = matrix_norm.topk(k,1) \n",
    "                  targetnodes_idx[targetnodes_idx>total_node-num_node-1] += num_node\n",
    "\n",
    "\n",
    "                  targetnodes_idx = torch.squeeze(targetnodes_idx.view(-1,1))\n",
    "                  curnodes_idx = torch.tensor(range(total_node-num_node, total_node)).repeat_interleave(k) #should not start from 0, but from numnode => change range()\n",
    "                  #curnodes_idx = curnodes_idx.to(device)\n",
    "                  edge_index = torch.stack((curnodes_idx, targetnodes_idx), dim = 1)\n",
    "                  edge_list.append(edge_index)\n",
    "\n",
    "          #Generate adjacency matrix \n",
    "              #node_embeddings = node_embeddings.to('cpu')\n",
    "              #adjacency_mat = torch.cat(edge_list, dim = 0).to('cpu') \n",
    "              adjacency_mat = torch.cat(edge_list, dim = 0) #adjacency_mat is for one graph of 15 frames \n",
    "              remove_list = []\n",
    "          #Create a graph based on node features and adjacency matrix, then add the graph to list\n",
    "              data = Data(x=node_embeddings, edge_index=adjacency_mat.t().contiguous())\n",
    "              nx_graph = utils.to_networkx(data)\n",
    "              to_remove = [(v,u) for v,u in nx_graph.edges() if not nx_graph.has_edge(u,v)]\n",
    "              nx_graph.remove_edges_from(to_remove)\n",
    "              data = utils.from_networkx(nx_graph)\n",
    "              data.x = node_embeddings\n",
    "\n",
    "\n",
    "          #######2. Generate edge attributes and add it to the graph\n",
    "              timestamp = torch.tensor(timestamp) #size K \n",
    "              boxes_info = torch.cat(list_boxes) #all_boxes: size Kx4\n",
    "              boxes_info[:,2] = boxes_info[:,2]-boxes_info[:,0]+1 #W\n",
    "              boxes_info[:,3] = boxes_info[:,3]-boxes_info[:,1]+1 #H\n",
    "\n",
    "              for edge in range(data.edge_index.shape[1]): \n",
    "                source_idx = data.edge_index[0,edge]\n",
    "                target_idx = data.edge_index[1,edge]\n",
    "                feat1 = 2*(boxes_info[target_idx,0]-boxes_info[source_idx,0])/(boxes_info[target_idx,3]+boxes_info[source_idx,3]) # 2(xj-xi)/(hi+hj)\n",
    "                feat2 = 2*(boxes_info[target_idx,1]-boxes_info[source_idx,1])/(boxes_info[target_idx,3]+boxes_info[source_idx,3])# 2(yj-yi)/(hi+hj)\n",
    "                feat3 = torch.log(boxes_info[source_idx,3]/boxes_info[target_idx,3]) #log(hi/hj)\n",
    "                feat4 = torch.log(boxes_info[source_idx,2]/boxes_info[target_idx,2]) #log (wi/wj)\n",
    "                feat5 = timestamp[target_idx] - timestamp[source_idx]\n",
    "                feat6 = (node_embeddings[target_idx]-node_embeddings[source_idx]).norm()\n",
    "                edge_feature = torch.tensor([feat1,feat2,feat3,feat4,feat5,feat6])\n",
    "                edge_features.append(edge_feature)\n",
    "              \n",
    "              #edge_features = torch.stack(edge_features).to(device)\n",
    "              edge_features = torch.stack(edge_features) #size Ex6, E: number of edges in the graph \n",
    "              print(edge_features.shape)\n",
    "              #edge_embeddings = edge_encoder(edge_features).to('cpu')\n",
    "              edge_embeddings = edge_encoder(edge_features)\n",
    "\n",
    "\n",
    "              data.edge_attr = edge_embeddings\n",
    "              graph_list.append(data)\n",
    "              print(\"Create one graph\")\n",
    "          \n",
    "          #Set lists to 0 and to start new graph\n",
    "              inc = 0\n",
    "              list_boxes = []\n",
    "              list_img = []\n",
    "              total_node = 0\n",
    "              edge_list = []\n",
    "              timestamp = []\n",
    "              edge_features = []\n",
    "              #crashed after using all available RAM. try to set all variables to None to solve problem\n",
    "              batch_images = None\n",
    "              detections = None\n",
    "              node_embeddings = None\n",
    "              current_nodes = None\n",
    "              other_nodes = None\n",
    "              matrix_norm = None\n",
    "              targetnodes_idx = None\n",
    "              data = None\n",
    "              edge_embeddings = None\n",
    "    return graph_list\n",
    "graph_list = load_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pmdWM-hNpIJ5",
    "outputId": "2b9b40be-83b9-4a8a-87e6-1b15677c8ded"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[5782, 16], edge_index=[2, 5782], x=[241, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "_NZ-v_tJ8vmM",
    "outputId": "5c3e0a70-a17b-4da7-a397-e5699d9838c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223,\n",
       "         223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223,\n",
       "         223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223,\n",
       "         223, 223, 223, 223, 224, 224, 224, 225, 225, 225, 225, 225, 225, 225,\n",
       "         225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225,\n",
       "         225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225,\n",
       "         225, 225, 226, 226, 226, 226, 226, 227, 227, 227, 227, 227, 227, 227,\n",
       "         227, 227],\n",
       "        [ 12, 235, 138,  21, 236, 231, 130, 163,  76,  55,  27,   6, 152,  49,\n",
       "          16, 187,  98,  51,  73, 201, 199, 113,  66,   5,  36,  88, 229, 148,\n",
       "         146,  57,  28, 122, 135,  83,  60, 190, 183,  13,  32, 234,  35,  61,\n",
       "         233, 177, 160, 166,  95, 219, 176,  71,  88,  43, 138,  41, 178,  57,\n",
       "         105,  50,  59,  83,  25,  19,  77,  47, 133,   3, 115, 181, 148, 150,\n",
       "         211,  66, 125,  92, 214,  60,   6, 189,  53, 139, 110, 190, 185, 200,\n",
       "           4, 156, 129, 118,  55,  91, 151,  62,  54, 210,  21, 163, 206,  90,\n",
       "          29,  12]])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list[0].edge_index[:,5000:5100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tPytBZOVBcqt"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from torchvision.ops import roi_align\n",
    "for seq in sequences:# Each seq is a MOT16Sequence object\n",
    "\n",
    "    print(f\"Tracking: {seq}\")\n",
    "    inc = 0\n",
    "    \n",
    "\n",
    "    data_loader = DataLoader(seq, batch_size=6, shuffle=False) #NOTE: shuffle  = False. This is order sequence !!!!\n",
    "    print(\"Done loading data\")\n",
    "    for batch_frame in tqdm(data_loader):\n",
    "        list_boxes, list_scores = obj_detect.detect(batch_frame['img'])\n",
    "        detections = roi_align(batch_frame['img'], list_boxes, (128,64))\n",
    "        break\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "from torchvision.ops import roi_align\n",
    "for seq in sequences:# Each seq is a MOT16Sequence object\n",
    "\n",
    "    print(f\"Tracking: {seq}\")\n",
    "    list_boxes = []\n",
    "    list_img = []\n",
    "    inc = 0\n",
    "    \n",
    "\n",
    "    data_loader = DataLoader(seq, batch_size=1, shuffle=False) #NOTE: shuffle  = False. This is order sequence !!!!\n",
    "    print(\"Done loading data\")\n",
    "    for frame in tqdm(data_loader):\n",
    "        boxes, scores = obj_detect.detect(frame['img'])\n",
    "        list_boxes.append(boxes)\n",
    "        list_img.append(torch.squeeze(frame['img']))\n",
    "        inc = inc+1\n",
    "        if inc==5: \n",
    "            break\n",
    "    batch_images = torch.stack(list_img)\n",
    "    detections = roi_align(batch_images, list_boxes, (128,64))\n",
    "\"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Test_MOTChallenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "motchallenge",
   "language": "python",
   "name": "motchallenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
